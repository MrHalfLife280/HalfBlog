<!DOCTYPE html><html lang="en-us"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>My opinions on AI - HalfBlog</title><meta name="description" content="Artificial Intelligence is probably one of the most overhyped, over-exaggerated, over-feared, and overpraised technologies that has ever existed. That’s not to say it isn’t important."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://mrhalflife280.github.io/HalfBlog/my-opinions-on-ai.html"><link rel="alternate" type="application/atom+xml" href="https://mrhalflife280.github.io/HalfBlog/feed.xml" title="HalfBlog - RSS"><link rel="alternate" type="application/json" href="https://mrhalflife280.github.io/HalfBlog/feed.json" title="HalfBlog - JSON"><meta property="og:title" content="My opinions on AI"><meta property="og:site_name" content="HalfBlog"><meta property="og:description" content="Artificial Intelligence is probably one of the most overhyped, over-exaggerated, over-feared, and overpraised technologies that has ever existed. That’s not to say it isn’t important."><meta property="og:url" content="https://mrhalflife280.github.io/HalfBlog/my-opinions-on-ai.html"><meta property="og:type" content="article"><link rel="preload" href="https://mrhalflife280.github.io/HalfBlog/assets/dynamic/fonts/jetbrainsmono/jetbrainsmono.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="https://mrhalflife280.github.io/HalfBlog/assets/dynamic/fonts/jetbrainsmono/jetbrainsmono-italic.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="https://mrhalflife280.github.io/HalfBlog/assets/css/style.css?v=0de5ed4b6a37ab1ddecf11b6f3d8bbb5"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://mrhalflife280.github.io/HalfBlog/my-opinions-on-ai.html"},"headline":"My opinions on AI","datePublished":"2025-05-17T11:46+02:00","dateModified":"2025-05-17T11:46+02:00","description":"Artificial Intelligence is probably one of the most overhyped, over-exaggerated, over-feared, and overpraised technologies that has ever existed. That’s not to say it isn’t important.","author":{"@type":"Person","name":"MrHalfLife","url":"https://mrhalflife280.github.io/HalfBlog/authors/mrhalflife/"},"publisher":{"@type":"Organization","name":"MrHalfLife"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><div class="container container--center"><header class="header"><div class="header__logo"><a class="logo" href="https://mrhalflife280.github.io/HalfBlog/">HalfBlog</a></div></header><main class="content"><article class="post"><header><h1 class="post__title">My opinions on AI</h1><div class="post__meta"><time datetime="2025-05-17T11:46" class="post__date">May 17, 2025 </time><span class="post__author"><a href="https://mrhalflife280.github.io/HalfBlog/authors/mrhalflife/" class="feed__author">MrHalfLife</a></span></div></header><div class="post__entry"><p data-pm-slice="1 1 []">Artificial Intelligence is probably one of the most overhyped, over-exaggerated, over-feared, and overpraised technologies that has ever existed.</p><p>That’s not to say it isn’t important. It <em>is</em> going to be a multi-billion-dollar industry—it probably already is. But I think people fundamentally misunderstand what AI actually is.</p><div><hr></div><h2>The Illusion of Intelligence</h2><p>AI people love to boost the hype because AI carries an illusion: the illusion that it's something greater than it actually is. But here’s my contention:</p><blockquote><p><strong>Artificial intelligence is just a computer program.</strong></p></blockquote><p>It takes inputs, gives outputs, and it's trained on massive datasets. But at its core, it's doing what any other computer program does. It may be more complex, but it's not fundamentally different.</p><div><hr></div><h2>AI Cults and the Extremes</h2><p>Some people have joined AI cults—either radically pro-AI or doom-and-gloom anti-AI.</p><p>There are people who genuinely believe AI will enslave and torture humanity. Others think it will solve every problem on Earth. Both camps are wrong.</p><p>The truth is more boring: AI is a tool, and like any other tool, it’s as good or bad as the way we use it.</p><div><hr></div><h2>The Real Danger</h2><p>Is AI going to destroy us? Will it fire off all the nukes?</p><p>Well, that depends on how <em>stupid</em> we are. If we design systems like nuclear arsenals without fail-safes, that’s on us—not the AI.</p><p>Thankfully, most nuclear systems are air-gapped, require physical keys, and have multiple analog fail-safes. AI isn’t inherently dangerous; poor system design is.</p><p>So no, AI isn’t going to press the red button unless we build a system dumb enough to let it.</p><div><hr></div><h2>The Seductive Illusion</h2><p>AI uses human language, and that’s the problem. People see it speak in fluent sentences and assume intelligence. But what it’s actually doing is <strong>syntactic manipulation</strong>—not semantic understanding.</p><p>It doesn't think. It doesn't know. It doesn’t "want" anything.</p><p>It’s like a giant, fancy autocorrect. And yet, when it produces unexpected or “creative” outputs, people assume it's wise or even conscious. That’s the illusion—and it's dangerous.</p><div><hr></div><h2>Calibration Matters</h2><p>A good example is the recent AI-assisted deciphering of ancient scrolls from Pompeii. AI was used to parse noisy 3D scans. But the real intelligence came from <strong>human calibration</strong>.</p><p>Humans tweaked and checked the results. If AI spit out nonsense, they rejected it. If it found actual Latin words, they confirmed and built on it. AI was just a tool in that process—not the translator.</p><p>This highlights a crucial point:</p><blockquote><p><strong>AI is only effective when it's properly calibrated.</strong></p></blockquote><p>You must be able to verify its answers. Otherwise, it’s just generating plausible-sounding gibberish.</p><div><hr></div><h2>AI’s Complexity = Its Unreliability</h2><p>When a simple program fails, we can debug it. When AI fails, we often <em>can’t</em> understand why. Worse, because it looks like it’s doing something smart, we hesitate to question it.</p><p>The bigger risk isn't what AI can do—it’s what people think it can do.</p><p>People see the output and assume intelligence, wisdom, or even consciousness. But really, it’s just high-level symbol manipulation. It has no understanding.</p><div><hr></div><h2>Statistics, Academia, and Rituals</h2><p>This illusion isn’t unique to AI. The same thing happens in academia, especially with statistics. People treat statistical rituals as if they carry truth just because they look scientific.</p><p>Null hypothesis testing is a great example. Most people using it don't understand it. It’s a ritual that adds a veneer of authority to ideas that may be completely wrong.</p><p>AI is falling into that same trap: a ritualistic process people trust more than their own judgment.</p><div><hr></div><h2>Mediocrity at Scale</h2><p>AI isn’t just misleading; it’s making the internet worse.</p><p>Search results are flooded with AI-generated slop—low-quality, uninspired, formulaic junk. It’s like spreading a teaspoon of butter over an entire loaf of bread: thin, tasteless, and unfulfilling.</p><p>People submit AI-generated content as if it's profound. They assume AI knows something they don’t. But the reality is much sadder—it’s not smart, and it’s not thinking.</p><div><hr></div><h2>My First AI Use</h2><p data-start="183" data-end="344">Recently, I used AI for the first time—<em data-start="222" data-end="233">seriously</em> used it. Not just asking dumb questions or making it write fanfic. I used it to help me <strong data-start="322" data-end="343">learn how to code</strong>.</p><p data-start="346" data-end="507">I didn’t know anything about web development. I didn’t know how HTML worked. But I wanted to make a website, and AI gave me just enough direction to get started.</p><p data-start="509" data-end="727">I started small. Just a basic page with some text and links. Then I learned how to style it with CSS. I figured out how to make buttons, layouts, and even forms. Now I can build <strong data-start="687" data-end="716">very simple HTML websites</strong> by myself.</p><p data-start="729" data-end="924">That moment—realizing I had made something, coded something, <em data-start="790" data-end="801">published</em> something—was powerful. Not because the AI was smart, but because I finally felt like I understood how the machine worked.</p><p data-start="926" data-end="1044">So no, AI didn’t do it for me. It pointed me in the right direction. But I still had to learn. I still had to <em data-start="1036" data-end="1043">build</em>.</p><p data-start="1046" data-end="1081">And now? I know how to make things.</p><div><hr></div><h2>Final Thoughts</h2><p>AI <em>feels</em> deep because it mimics human language, but it’s a blind machine. It has no idea what it's saying. The real danger isn’t in the tech—it's in how we <em>perceive</em> it.</p><blockquote><p><strong>AI is dangerous because people trust it, not because of what it is.</strong></p></blockquote><p>It gives us the illusion of depth, the illusion of wisdom, and people buy into that illusion. That’s what makes it powerful—and potentially harmful.</p><p>And yeah, maybe it's demonic. But that's another video.</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on May 17, 2025</p><div class="post__share"></div></footer><nav class="pagination"><div class="pagination__title"><span>Read other posts</span></div><div class="pagination__buttons"><a href="https://mrhalflife280.github.io/HalfBlog/when-losers-have-lost-their-minds-bigots.html" class="btn previous" rel="prev" aria-label="[MISSING TRANSLATION]:  When losers have lost their minds (Bigots) "><span class="btn__icon">←</span> <span class="btn__text">When losers have lost their minds (Bigots)</span></a></div></nav></article></main><footer class="footer"><div class="footer__inner"><div class="footer__copyright"><p>© 2025 Powered by Publii CMS :: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank" rel="noopener">Theme</a> ported by the <a href="https://getpublii.com/customization-service/" target="_blank" rel="noopener">Publii Team</a></p></div></div></footer></div><script defer="defer" src="https://mrhalflife280.github.io/HalfBlog/assets/js/scripts.min.js?v=c2232aa7558e9517946129d2a1b8c770"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>